# VisualSentimentAnalysis
In recent years, a lot of progress has been made in the field of sentiment analysis. Researchers used textual data, but they have only recently begun to  look  into methods  for predicting sentiments  from  multimedia material. Increasingly, users of social  media use images and videos to communicate their views and share their experiences. With the mounting amount of data exchanged on social media, there is a growing interest in evaluating the emotions they induce on the audience. Sentiment analysis of such large-scale visual  content  will  aid  in  better  extracting  user  sentiments  against  events  or  subjects,  such  as  those  in  image  tweets  so  that sentiment prediction from visual content can be used in conjunction with sentiment analysis of textual content. While significant development has beenmade with this technology, little research has been done on the picture sentiments. A formalization of the issue is addressed, taking into account various levels of granularity as well as the various components that can influence sentiment related to the image. The purpose of this work is to focus on determining the sentiment polarity (positive, negative, or neutral) of a given  image.  We  tackled  the  problem  of  training  visual  sentiment  classifiers  from  a  wide  collection  of  user-generated  image content. By performing comparative studies and analysis on a benchmark for visual sentiment analysis, we were able to discern the validity of our models. Our empirical study shows that the image content can be used to train deep Convolutional Neural Networks that effectively predict the sentiment polarity of previously unseen photos. These predictions can be used in applications such as automated tag predictions for images posted to social media platforms and understanding the sentiment of people.
